\documentclass[aspectratio=169]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{rotating}

% Tema
\usecolortheme{default}

% Configurazione listing Python
\lstset{

	basicstyle=\ttfamily\small,
	keywordstyle=\color{blue}\bfseries,
	commentstyle=\color{gray}\itshape,
	stringstyle=\color{red},
	showstringspaces=false,
	breaklines=true,
	frame=single,
	numbers=left,
	numberstyle=\tiny\color{gray},
	backgroundcolor=\color{gray!10}
}

% Informazioni
\title{Machine Learning con Scikit-Learn}
\subtitle{Previsione del Diabete}
\author{Prof. Massimo Fedeli}
\institute{IIS Fermi Sacconi Ceci - Ascoli Piceno}
\date{\today}

\begin{document}
	
	% Slide 1: Titolo
	\begin{frame}
		\titlepage
	\end{frame}
	
	% Slide 2: Indice
	\begin{frame}{Contenuti}
		\tableofcontents
	\end{frame}
	
	% Slide 3: Introduzione
	\section{Introduzione}
	\begin{frame}{Dal Classification al Problema Reale}
		\begin{block}{Cosa abbiamo imparato}
			Con l'esercizio Iris abbiamo classificato fiori in base a misure fisiche.
		\end{block}
		
		\vspace{0.5cm}
		
		\begin{block}{Oggi: Un Problema Medico Reale}
			Useremo il Machine Learning per \textbf{predire il rischio di diabete} in base a parametri medici.
		\end{block}
		
		\vspace{0.5cm}
		
		\begin{columns}
			\column{0.5\textwidth}
			\textbf{Iris (esercizio precedente):}
			\begin{itemize}
				\item 3 classi (specie)
				\item 4 features (misure)
				\item 150 campioni
				\item Decision Tree
			\end{itemize}
			
			\column{0.5\textwidth}
			\textbf{Diabete (oggi):}
			\begin{itemize}
				\item 2 classi (sì/no)
				\item 10 features (parametri medici)
				\item 442 campioni
				\item Logistic Regression
			\end{itemize}
		\end{columns}
	\end{frame}
	
	% Slide 4: Il Diabete
	\begin{frame}{Il Diabete: Contesto Medico}
		\begin{block}{Cos'è il Diabete?}
			Malattia cronica caratterizzata da elevati livelli di glucosio nel sangue.
		\end{block}
		
		\vspace{0.3cm}
		
		\begin{columns}
			\column{0.6\textwidth}
			\textbf{Fattori di rischio:}
			\begin{itemize}
				\item Età
				\item Peso corporeo (BMI)
				\item Pressione sanguigna
				\item Livelli di colesterolo
				\item Livelli di glucosio
				\item Storia familiare
			\end{itemize}
			
			\column{0.4\textwidth}
			\begin{center}
				\begin{tikzpicture}[scale=0.7]
					% Glucometro stilizzato
					\draw[fill=blue!20, rounded corners] (0,0) rectangle (3,4);
					\draw[fill=white] (0.5,2.5) rectangle (2.5,3.5);
					\node at (1.5,3) {\Large \textbf{140}};
					\node at (1.5,2.2) {\small mg/dL};
					\draw[fill=red!50] (0.8,0.5) rectangle (2.2,0.8);
					\draw[fill=green!50] (0.8,1.2) rectangle (2.2,1.5);
				\end{tikzpicture}
			\end{center}
		\end{columns}
		
		\vspace{0.3cm}
		
		\begin{alertblock}{Importanza della Prevenzione}
			La diagnosi precoce può prevenire complicazioni gravi!
		\end{alertblock}
	\end{frame}
	
	% Slide 5: Il Dataset
	\section{Il Dataset Diabetes}
	\begin{frame}{Il Dataset Pima Indians Diabetes}
		\begin{block}{Origine}
			Dataset medico contenente dati di 442 pazienti con misurazioni cliniche.
		\end{block}
		
		\vspace{0.3cm}
		
		\textbf{Caratteristiche del dataset:}
		\begin{itemize}
			\item \textbf{442 campioni} (pazienti)
			\item \textbf{10 features} (parametri medici normalizzati)
			\item \textbf{Target}: valore numerico di progressione del diabete
		\end{itemize}
		
		\vspace{0.3cm}
		
		\begin{exampleblock}{Nota Importante}
			Il dataset originale è per \textit{regressione}. Noi lo trasformeremo in un problema di \textit{classificazione binaria}:
			\begin{itemize}
				\item Classe 0: Nessun diabete (target $\leq$ 140)
				\item Classe 1: Diabete (target $>$ 140)
			\end{itemize}
		\end{exampleblock}
	\end{frame}
	
	% Slide 6: Le 10 Features
	\begin{frame}{Le 10 Features del Dataset}
		\begin{center}
			\begin{tikzpicture}
				\node[draw, rectangle, fill=blue!20, minimum width=10cm, minimum height=1cm] at (0,3.5) 
				{\textbf{Features (X)} - Parametri Medici Misurati};
				
				% Colonna sinistra
				\node[draw, rectangle, fill=green!20, minimum width=4.5cm, text width=4cm, align=center] at (-2.75,2.3) 
				{1. Età};
				\node[draw, rectangle, fill=green!20, minimum width=4.5cm, text width=4cm, align=center] at (-2.75,1.6) 
				{2. Sesso};
				\node[draw, rectangle, fill=orange!20, minimum width=4.5cm, text width=4cm, align=center] at (-2.75,0.9) 
				{3. BMI (Indice massa corporea)};
				\node[draw, rectangle, fill=orange!20, minimum width=4.5cm, text width=4cm, align=center] at (-2.75,0.2) 
				{4. Pressione sanguigna media};
				\node[draw, rectangle, fill=purple!20, minimum width=4.5cm, text width=4cm, align=center] at (-2.75,-0.5) 
				{5. S1 - Colesterolo totale};
				
				% Colonna destra
				\node[draw, rectangle, fill=purple!20, minimum width=4.5cm, text width=4cm, align=center] at (2.75,2.3) 
				{6. S2 - LDL (cattivo)};
				\node[draw, rectangle, fill=purple!20, minimum width=4.5cm, text width=4cm, align=center] at (2.75,1.6) 
				{7. S3 - HDL (buono)};
				\node[draw, rectangle, fill=purple!20, minimum width=4.5cm, text width=4cm, align=center] at (2.75,0.9) 
				{8. S4 - Trigliceridi};
				\node[draw, rectangle, fill=cyan!20, minimum width=4.5cm, text width=4cm, align=center] at (2.75,0.2) 
				{9. S5 - Livello glucosio};
				\node[draw, rectangle, fill=cyan!20, minimum width=4.5cm, text width=4cm, align=center] at (2.75,-0.5) 
				{10. S6 - Altro parametro};
				
				\node[draw, rectangle, fill=red!20, minimum width=10cm, minimum height=0.8cm] at (0,-1.3) 
				{\textbf{Target (y)} - Rischio diabete: 0 (no) o 1 (sì)};
			\end{tikzpicture}
		\end{center}
		
		\vspace{0.2cm}
		\begin{alertblock}{Nota}
			I valori sono \textbf{normalizzati} (standardizzati tra -0.2 e 0.2 circa)
		\end{alertblock}
	\end{frame}
	
	% Slide 7: Classificazione Binaria
	\begin{frame}{Da Regressione a Classificazione Binaria}
		\begin{columns}
			\column{0.5\textwidth}
			\textbf{Dataset Originale:}
			\begin{itemize}
				\item Target: valore continuo
				\item Range: 25-346
				\item Tipo: Regressione
			\end{itemize}
			
			\vspace{0.5cm}
			
			\textbf{Soglia scelta: 140}
			
			\column{0.5\textwidth}
			\textbf{Nostra Trasformazione:}
			\begin{itemize}
				\item Target: 0 o 1
				\item 0 = Nessun diabete
				\item 1 = Diabete
				\item Tipo: Classificazione
			\end{itemize}
		\end{columns}
		
		\vspace{0.5cm}
		
		\begin{center}
			\begin{tikzpicture}
				% Linea continua
				\draw[thick, ->] (0,0) -- (8,0);
				\node at (4,-0.5) {Valore Target Originale};
				
				% Soglia
				\draw[red, very thick] (4,0) -- (4,1.5);
				\node[red] at (4,1.8) {\textbf{140}};
				
				% Zone
				\draw[fill=green!30] (0,0.2) rectangle (4,0.8);
				\node at (2,0.5) {\textbf{Classe 0}};
				
				\draw[fill=red!30] (4,0.2) rectangle (8,0.8);
				\node at (6,0.5) {\textbf{Classe 1}};
				
				% Etichette
				\node at (0,-0.3) {25};
				\node at (8,-0.3) {346};
			\end{tikzpicture}
		\end{center}
	\end{frame}
	
	% Slide 8: Logistic Regression
	\section{Logistic Regression}
	\begin{frame}{Logistic Regression: Il Modello}
		\begin{block}{Cos'è?}
			Algoritmo di classificazione che calcola la \textbf{probabilità} che un campione appartenga a una classe.
		\end{block}
		
		\vspace{0.3cm}
		
		\begin{columns}
			\column{0.6\textwidth}
			\textbf{Differenze con Decision Tree:}
			\begin{itemize}
				\item Non crea un albero
				\item Calcola probabilità (0-100\%)
				\item Usa una funzione sigmoide
				\item Migliore per problemi medici
			\end{itemize}
			
			\vspace{0.3cm}
			
			\textbf{Soglia di decisione:}
			\begin{itemize}
				\item Probabilità $\geq$ 50\% → Classe 1
				\item Probabilità $<$ 50\% → Classe 0
			\end{itemize}
			
			\column{0.4\textwidth}
			\begin{center}
				\begin{tikzpicture}[scale=0.8]
					% Funzione sigmoide
					\draw[->] (-2,0) -- (2,0) node[right] {x};
					\draw[->] (0,-0.5) -- (0,3.5) node[above] {P(y=1)};
					
					\draw[blue, thick, domain=-2:2, samples=100] 
					plot (\x, {3/(1+exp(-3*\x))});
					
					\draw[dashed] (-2,1.5) -- (2,1.5);
					\node[left] at (-2,1.5) {0.5};
					
					\node at (0,-1) {\small Funzione Sigmoide};
				\end{tikzpicture}
			\end{center}
		\end{columns}
	\end{frame}
	
	% Slide 9: Il Processo
	\section{Implementazione}
	\begin{frame}{Il Processo di Machine Learning}
		\begin{center}
			\begin{tikzpicture}[node distance=2.2cm, auto]
				\node[draw, rectangle, fill=blue!20, text width=2.5cm, align=center] (load) {1. Carica\\Dataset};
				\node[draw, rectangle, fill=green!20, text width=2.5cm, align=center, right of=load, node distance=3.2cm] (transform) {2. Trasforma\\in Binario};
				\node[draw, rectangle, fill=orange!20, text width=2.5cm, align=center, below of=transform] (split) {3. Dividi\\Train/Test};
				\node[draw, rectangle, fill=purple!20, text width=2.5cm, align=center, left of=split, node distance=3.2cm] (train) {4. Addestra\\Modello};
				\node[draw, rectangle, fill=cyan!20, text width=2.5cm, align=center, below of=train] (predict) {5. Fai\\Predizioni};
				\node[draw, rectangle, fill=red!20, text width=2.5cm, align=center, right of=predict, node distance=3.2cm] (evaluate) {6. Valuta\\Risultati};
				
				\draw[->, thick] (load) -- (transform);
				\draw[->, thick] (transform) -- (split);
				\draw[->, thick] (split) -- (train);
				\draw[->, thick] (train) -- (predict);
				\draw[->, thick] (predict) -- (evaluate);
			\end{tikzpicture}
		\end{center}
		
		\vspace{0.5cm}
		
		\begin{alertblock}{Novità rispetto a Iris}
			Prima di dividere i dati, trasformiamo il target in classificazione binaria!
		\end{alertblock}
	\end{frame}
	
	% Slide 10: Codice - Caricamento
	\begin{frame}[fragile]{Passo 1 e 2: Caricamento e Trasformazione}
		\begin{lstlisting}
			from sklearn.datasets import load_diabetes
			import numpy as np
			
			# Carica il dataset
			diabetes = load_diabetes()
			X = diabetes.data          # 442 campioni x 10 features
			y_continuous = diabetes.target  # Valori continui (25-346)
			
			# Trasforma in classificazione binaria
			y = (y_continuous > 140).astype(int)
			# y_continuous > 140 restituisce True/False
			# .astype(int) converte in 1/0
			
			print(f"Campioni totali: {len(X)}")
			print(f"Pazienti con diabete: {np.sum(y == 1)}")
			print(f"Pazienti senza diabete: {np.sum(y == 0)}")
		\end{lstlisting}
		
		\vspace{0.2cm}
		
		\begin{block}{Output}
			\texttt{Campioni totali: 442} \\
			\texttt{Pazienti con diabete: 220} \\
			\texttt{Pazienti senza diabete: 222}
		\end{block}
	\end{frame}
	
	% Slide 11: Codice - Split e Training
	\begin{frame}[fragile]{Passo 3 e 4: Split e Addestramento}
		\begin{lstlisting}
			from sklearn.model_selection import train_test_split
			from sklearn.linear_model import LogisticRegression
			
			# Dividi i dati (75% training, 25% test)
			X_train, X_test, y_train, y_test = train_test_split(
			X, y, test_size=0.25, random_state=42
			)
			
			# Crea il modello Logistic Regression
			model = LogisticRegression(max_iter=1000, random_state=42)
			
			# Addestra il modello
			model.fit(X_train, y_train)
		\end{lstlisting}
		
		\vspace{0.3cm}
		
		\begin{block}{Perché \texttt{max\_iter=1000}?}
			Logistic Regression usa un algoritmo iterativo. \texttt{max\_iter} specifica il numero massimo di iterazioni per convergere alla soluzione ottimale.
		\end{block}
	\end{frame}
	
	% Slide 12: Codice - Predizioni e Accuratezza
	\begin{frame}[fragile]{Passo 5 e 6: Predizioni e Valutazione}
		\begin{lstlisting}
			from sklearn.metrics import accuracy_score
			
			# Fai predizioni sul test set
			y_pred = model.predict(X_test)
			
			# Calcola l'accuratezza
			accuracy = accuracy_score(y_test, y_pred)
			print(f"Accuratezza: {accuracy:.2%}")
			
			# Output: Accuratezza: 75.45%
		\end{lstlisting}
		
		\vspace{0.3cm}
		
		\begin{exampleblock}{Interpretazione}
			Il modello classifica correttamente il 75\% dei pazienti nel test set.
			\begin{itemize}
				\item Su 111 pazienti di test
				\item Ne classifica correttamente circa 84
				\item Ne sbaglia circa 27
			\end{itemize}
		\end{exampleblock}
	\end{frame}
	
	% Slide 13: Matrice di Confusione
	\begin{frame}[fragile]{La Matrice di Confusione}
		\begin{columns}
			\column{0.5\textwidth}
			\begin{lstlisting}[numbers=none]
				from sklearn.metrics import confusion_matrix
				
				conf_matrix = confusion_matrix(
				y_test, y_pred
				)
				print(conf_matrix)
				
				# Output:
				# [[45 10]
				#  [17 39]]
			\end{lstlisting}
			
			\column{0.5\textwidth}
			\begin{center}
				\begin{tabular}{cc|c|c|}
					\multicolumn{2}{c}{} & \multicolumn{2}{c}{\textbf{Predetto}} \\
					\cline{3-4}
					\multicolumn{2}{c|}{} & \textbf{No (0)} & \textbf{Sì (1)} \\
					\cline{2-4}
					\multirow{2}{*}{\rotatebox{90}{\textbf{Reale}}} & \textbf{No (0)} & \cellcolor{green!30}45 & \cellcolor{red!30}10 \\
					\cline{2-4}
					& \textbf{Sì (1)} & \cellcolor{red!30}17 & \cellcolor{green!30}39 \\
					\cline{2-4}
				\end{tabular}
			\end{center}
		\end{columns}
		
		\vspace{0.5cm}
		
		\textbf{Interpretazione:}
		\begin{itemize}
			\item \textbf{45}: Correttamente classificati come "No diabete" (True Negative)
			\item \textbf{39}: Correttamente classificati come "Diabete" (True Positive)
			\item \textbf{10}: Erroneamente classificati come "Diabete" (False Positive)
			\item \textbf{17}: Erroneamente classificati come "No diabete" (False Negative) ⚠️
		\end{itemize}
	\end{frame}
	
	% Slide 14: Metriche Avanzate
	\begin{frame}[fragile]{Metriche di Valutazione Avanzate}
		\begin{lstlisting}[numbers=none]
			from sklearn.metrics import classification_report
			
			print(classification_report(y_test, y_pred, 
			target_names=['No Diabete', 'Diabete']))
		\end{lstlisting}
		
		\begin{center}
			\begin{tabular}{lcccc}
				\toprule
				& \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\
				\midrule
				No Diabete & 0.73 & 0.82 & 0.77 & 55 \\
				Diabete & 0.80 & 0.70 & 0.74 & 56 \\
				\midrule
				\textbf{Accuracy} & & & \textbf{0.75} & 111 \\
				\bottomrule
			\end{tabular}
		\end{center}
		
		\vspace{0.3cm}
		
		\textbf{Definizioni:}
		\begin{itemize}
			\item \textbf{Precision}: Di tutti i casi predetti positivi, quanti sono corretti?
			\item \textbf{Recall}: Di tutti i casi realmente positivi, quanti ne abbiamo trovati?
			\item \textbf{F1-Score}: Media armonica di precision e recall
		\end{itemize}
	\end{frame}
	
	% Slide 15: Test Nuovo Paziente
	\begin{frame}[fragile]{Testare un Nuovo Paziente}
		\begin{lstlisting}
			# Dati di un nuovo paziente (valori normalizzati)
			nuovo_paziente = [[0.05, -0.04, 0.06, -0.04, -0.01, 
			-0.03, 0.04, 0.00, 0.09, 0.03]]
			
			# Fai la predizione
			predizione = model.predict(nuovo_paziente)
			
			# Visualizza il risultato
			print(f"Predizione: {predizione[0]}")
			if predizione[0] == 1:
			print("⚠️  Rischio diabete")
			else:
			print("✓ Nessun rischio diabete")
			
			# Output: 
			# Predizione: 1
			# ⚠️  Rischio diabete
		\end{lstlisting}
		
		\begin{alertblock}{Applicazione Pratica}
			Il modello può essere usato come strumento di screening per identificare pazienti a rischio che necessitano ulteriori esami.
		\end{alertblock}
	\end{frame}
	
	% Slide 16: Conclusioni
	\section{Conclusioni}
	\begin{frame}{Riepilogo e Riflessioni}
		\textbf{Cosa abbiamo imparato:}
		\begin{itemize}
			\item Trasformare un problema di regressione in classificazione
			\item Usare Logistic Regression per problemi binari
			\item Interpretare la matrice di confusione
			\item Valutare modelli con metriche avanzate (precision, recall)
			\item Applicare ML a problemi medici reali
		\end{itemize}
		
		\vspace{0.4cm}
		
		\textbf{Confronto Iris vs Diabete:}
		\begin{center}
			\begin{tabular}{lcc}
				\toprule
				& \textbf{Iris} & \textbf{Diabete} \\
				\midrule
				Classi & 3 & 2 \\
				Accuratezza & $\sim$100\% & $\sim$75\% \\
				Modello & Decision Tree & Logistic Regression \\
				Difficoltà & Facile & Media \\
				\bottomrule
			\end{tabular}
		\end{center}
		
		\vspace{0.3cm}
		
		\begin{block}{Perché accuratezza più bassa?}
			I dati medici sono più complessi e hanno più "rumore" rispetto a misure botaniche.
		\end{block}
	\end{frame}
	
	% Slide 17: Esercizi
	\begin{frame}{Esercizi per Casa}
		\textbf{Esercizi base:}
		\begin{enumerate}
			\item Prova a cambiare la soglia (es. 120 o 160) e osserva come cambia l'accuratezza
			\item Confronta Logistic Regression con Decision Tree sullo stesso dataset
			\item Calcola la percentuale di False Negative (molto importanti in medicina!)
		\end{enumerate}
		
		\vspace{0.3cm}
		
		\textbf{Esercizi avanzati:}
		\begin{enumerate}
			\item Usa \texttt{RandomForestClassifier} e confronta i risultati
			\item Visualizza la matrice di confusione con \texttt{seaborn.heatmap}
			\item Calcola e visualizza la curva ROC
			\item Trova quali features sono più importanti per la predizione
		\end{enumerate}
		
		\vspace{0.5cm}
		
		\begin{center}
			\Large{\textbf{Domande?}}
		\end{center}
	\end{frame}
	
\end{document}